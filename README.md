# Introduction-to-Deep-Learning-and-Neural-Networks-with-Keras
https://www.coursera.org/learn/introduction-to-deep-learning-with-keras?

### Understanding Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss and all those confusing names
https://gombru.github.io/2018/05/23/cross_entropy_loss/


### Gradient

The gradient of a function is the slope of its derivative (line), or in other words, the rate of change of a function. It's a vector (a direction to move) that points in the direction of greatest increase of the function, and calculated by the derivative operation.
